{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Early Onset PD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duwadisudan/Collaborative_deep_learning/blob/main/Early_Onset_PD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRy9p80zeKNh"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcmFSvaAfCl3"
      },
      "source": [
        "vols = sio.loadmat('http://bspl.korea.ac.kr/Research_data/sensorimotor/sensorimotor_4D_sample.mat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMmNwD_SdyWX"
      },
      "source": [
        "X_train, X_test, y_train, y_test = vols['X_train'], vols['X_test'], vols['y_train'], vols['y_test']\n",
        "n_classes = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKuiA79ad0tW"
      },
      "source": [
        "print(np.shape(X_train),np.shape(X_test),np.shape(y_train),np.shape(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DERoP5pMcvV2"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYIkN6X1cz9h"
      },
      "source": [
        "x_mean = np.mean(X_train)\n",
        "x_std = np.std(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjVoheeic38H"
      },
      "source": [
        "X_tr_centered = (X_train - x_mean)/x_std\n",
        "X_ts_centered = (X_test - x_mean)/x_std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-vdg7jxc6RH"
      },
      "source": [
        "y_train = y_train.flatten()\n",
        "y_test = y_test.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf970-Akc86k"
      },
      "source": [
        "X_tr_centered.shape,  X_ts_centered.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdZ0xB4fc-5_"
      },
      "source": [
        "np.std(X_ts_centered)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKb-l3erdA2X"
      },
      "source": [
        "plt.imshow(X_tr_centered[1,:,:,40])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNZ_1wzJdHhG"
      },
      "source": [
        "def batch_generator(X, y, batch_size=50, \n",
        "                    shuffle=True, random_seed=None):\n",
        "    \n",
        "    idx = np.arange(y.shape[0])\n",
        "    \n",
        "    if shuffle:\n",
        "        rng = np.random.RandomState(random_seed)\n",
        "        rng.shuffle(idx)\n",
        "        X = X[idx]\n",
        "        y = y[idx]\n",
        "    \n",
        "    for i in range(0, X.shape[0], batch_size):\n",
        "        yield (X[i:i+batch_size, :], y[i:i+batch_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePNjh0LqdIUS"
      },
      "source": [
        "class Conv3dNN(object):\n",
        "    def __init__(self, n_classes=4, batchsize=50,\n",
        "                 epochs=100, learning_rate=1e-4, \n",
        "                 dropout_rate=0.5,\n",
        "                 shuffle=True, random_seed=None):\n",
        "        np.random.seed(random_seed)\n",
        "        self.batchsize = batchsize\n",
        "        self.epochs = epochs\n",
        "        self.learning_rate = learning_rate\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.shuffle = shuffle\n",
        "        self.n_classes = n_classes\n",
        "                \n",
        "        g = tf.Graph()\n",
        "        with g.as_default():\n",
        "            ## set random-seed:\n",
        "            tf.set_random_seed(random_seed)\n",
        "            \n",
        "            ## build the network:\n",
        "            self.build()\n",
        "\n",
        "            ## initializer\n",
        "            self.init_op = \\\n",
        "                tf.global_variables_initializer()\n",
        "\n",
        "            ## saver\n",
        "            self.saver = tf.train.Saver()\n",
        "            \n",
        "        ## create a session\n",
        "        self.sess = tf.Session(graph=g)\n",
        "                \n",
        "    def build(self):\n",
        "        \n",
        "        ## Placeholders for X and y:\n",
        "        tf_x = tf.placeholder(tf.float32, \n",
        "                              shape=[None, 53, 63, 46],\n",
        "                              name='tf_x')\n",
        "        tf_y = tf.placeholder(tf.int32, \n",
        "                              shape=[None],\n",
        "                              name='tf_y')\n",
        "        is_train = tf.placeholder(tf.bool, \n",
        "                              shape=(),\n",
        "                              name='is_train')\n",
        "        \n",
        "        ## reshape x to 5D tensor:\n",
        "        ## [batchsize, x, y, z, 1]\n",
        "        tf_x_vol = tf.reshape(tf_x, shape=[-1, 53, 63, 46, 1],\n",
        "                             name='input_x_3d_volumes')\n",
        "\n",
        "        ## One-hot encoding:\n",
        "        tf_y_onehot = tf.one_hot(indices=tf_y, depth=4,\n",
        "                              dtype=tf.float32,\n",
        "                              name='input_y_onehot')\n",
        "\n",
        "        ## 1st layer: Conv_1\n",
        "        h1 = tf.layers.conv3d(tf_x_vol, \n",
        "                              filters=8, \n",
        "                              kernel_size=(7, 7, 7), \n",
        "                              strides=(1, 1, 1),\n",
        "                              padding='valid',\n",
        "                              activation=tf.nn.relu)\n",
        "        ## MaxPooling\n",
        "        h1_pool = tf.layers.max_pooling3d(h1, \n",
        "                              pool_size=(2, 2, 2), \n",
        "                              strides=(2, 2, 2))\n",
        "        \n",
        "        ## 2nd layer: Conv_2\n",
        "        h2 = tf.layers.conv3d(h1_pool, \n",
        "                              filters=16, \n",
        "                              kernel_size=(5, 5, 5), \n",
        "                              strides=(1,1,1),\n",
        "                              padding='valid',\n",
        "                              activation=tf.nn.relu)\n",
        "        ## MaxPooling \n",
        "        h2_pool = tf.layers.max_pooling3d(h2, \n",
        "                              pool_size=(2, 2, 2), \n",
        "                              strides=(2, 2, 2))\n",
        "\n",
        "        ## 3rd layer: Conv_3\n",
        "        h3 = tf.layers.conv3d(h2_pool, \n",
        "                              filters=32, \n",
        "                              kernel_size=(3, 3, 3), \n",
        "                              strides=(1,1,1),\n",
        "                              padding='valid',\n",
        "                              activation=tf.nn.relu)\n",
        "        ## MaxPooling \n",
        "        h3_pool = tf.layers.max_pooling3d(h3, \n",
        "                              pool_size=(2, 2, 2), \n",
        "                              strides=(2, 2, 2))\n",
        "        \n",
        "        ## 4th layer: Fully Connected\n",
        "        input_shape = h3_pool.get_shape().as_list()\n",
        "        n_input_units = np.prod(input_shape[1:])\n",
        "        h3_pool_flat = tf.reshape(h3_pool, \n",
        "                              shape=[-1, n_input_units])\n",
        "        \n",
        "        h4 = tf.layers.dense(h3_pool_flat, 128, \n",
        "                              activation=tf.nn.relu)\n",
        "\n",
        "        ## Dropout\n",
        "        h4_drop = tf.layers.dropout(h4, \n",
        "                              rate=self.dropout_rate,\n",
        "                              training=is_train)\n",
        "        \n",
        "        ## 5th layer: Fully Connected (linear activation)\n",
        "        h5 = tf.layers.dense(h4_drop, self.n_classes, \n",
        "                              activation=tf.nn.sigmoid)\n",
        "\n",
        "        ## Prediction\n",
        "        predictions = {\n",
        "            'probabilities': tf.nn.softmax(h5, \n",
        "                              name='probabilities'),\n",
        "            'labels': tf.cast(tf.argmax(h5, axis=1), \n",
        "                              tf.int32, name='labels')}\n",
        "        \n",
        "        ## Loss Function and Optimization\n",
        "        cross_entropy_loss = tf.reduce_mean(\n",
        "            tf.nn.softmax_cross_entropy_with_logits(\n",
        "                logits=h5, labels=tf_y_onehot),\n",
        "            name='cross_entropy_loss')\n",
        "        \n",
        "        ## Optimizer:\n",
        "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
        "        optimizer = optimizer.minimize(cross_entropy_loss,\n",
        "                              name='train_op')\n",
        "\n",
        "        ## Finding accuracy\n",
        "        correct_predictions = tf.equal(\n",
        "            predictions['labels'], \n",
        "            tf_y, name='correct_preds')\n",
        "        \n",
        "        accuracy = tf.reduce_mean(\n",
        "            tf.cast(correct_predictions, tf.float32),\n",
        "            name='accuracy')\n",
        "\n",
        "    def save(self, epoch, path='./CNN3d-tflayers-model/'):\n",
        "        if not os.path.isdir(path):\n",
        "            os.makedirs(path)\n",
        "        print('Saving model in %s' % path)\n",
        "        self.saver.save(self.sess, \n",
        "                        os.path.join(path, 'model.ckpt'),\n",
        "                        global_step=epoch)\n",
        "        \n",
        "    def load(self, epoch, path):\n",
        "        print('Loading model from %s' % path)\n",
        "        self.saver.restore(self.sess, \n",
        "             os.path.join(path, 'model.ckpt-%d' % epoch))\n",
        "        \n",
        "    def train(self, training_set, \n",
        "              validation_set=None,\n",
        "              initialize=True):\n",
        "        ## initialize variables\n",
        "        if initialize:\n",
        "            self.sess.run(self.init_op)\n",
        "\n",
        "        self.train_cost_ = []\n",
        "        X_data_tr = np.array(training_set[0])\n",
        "        y_data_tr = np.array(training_set[1])\n",
        "\n",
        "        for epoch in range(1, self.epochs + 1):\n",
        "            batch_gen_tr = \\\n",
        "                batch_generator(X_data_tr, y_data_tr, batch_size=self.batchsize, \n",
        "                                 shuffle=self.shuffle)\n",
        "            avg_loss = 0.0\n",
        "            for i, (batch_x,batch_y) in \\\n",
        "                enumerate(batch_gen_tr):\n",
        "                feed = {'tf_x:0': batch_x, \n",
        "                        'tf_y:0': batch_y,\n",
        "                        'is_train:0': True} ## for dropout\n",
        "                loss, _ = self.sess.run(\n",
        "                        ['cross_entropy_loss:0', 'train_op'], \n",
        "                        feed_dict=feed)\n",
        "                avg_loss += loss\n",
        "                \n",
        "            print('Epoch %02d: Training Avg. Loss: '\n",
        "                  '%7.3f' % (epoch, avg_loss), end=' ')\n",
        "            if validation_set is not None:\n",
        "                \n",
        "                X_data_ts = np.array(training_set[0])\n",
        "                y_data_ts = np.array(training_set[1])\n",
        "                # test accuracy\n",
        "                batch_gen_ts = \\\n",
        "                batch_generator(X_data_ts, y_data_ts,\n",
        "                                 shuffle=False,batch_size=self.batchsize)\n",
        "                avg_valid_acc = 0.0\n",
        "                for i, (batch_x,batch_y) in \\\n",
        "                    enumerate(batch_gen_ts):\n",
        "                    feed = {'tf_x:0': batch_x,\n",
        "                            'tf_y:0': batch_y,\n",
        "                            'is_train:0': False} ## for dropout\n",
        "                    avg_valid_acc = avg_valid_acc + self.sess.run('accuracy:0', feed_dict=feed)\n",
        "                avg_valid_acc = avg_valid_acc/(i+1)\n",
        "                \n",
        "                print('Validation Acc: %7.3f' % avg_valid_acc)\n",
        "            else:\n",
        "                print()\n",
        "                    \n",
        "    def predict(self, X_test, return_proba = False):\n",
        "        feed = {'tf_x:0': X_test,\n",
        "                'is_train:0': False} ## for dropout\n",
        "        if return_proba:\n",
        "            return self.sess.run('probabilities:0',\n",
        "                                 feed_dict=feed)\n",
        "        else:\n",
        "            return self.sess.run('labels:0',\n",
        "                                 feed_dict=feed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RvNBVUfdMKn"
      },
      "source": [
        "cnn3d = Conv3dNN(random_seed=123, epochs=50, n_classes=n_classes)\n",
        "\n",
        "cnn3d.train(training_set=(X_tr_centered, y_train), \n",
        "         validation_set=(X_ts_centered, y_test))\n",
        "\n",
        "cnn3d.save(epoch=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oflzxttSdk0p"
      },
      "source": [
        "\n",
        "del cnn3d\n",
        "\n",
        "cnn3d_re = Conv3dNN(random_seed=123)\n",
        "cnn3d_re.load(epoch=50, path='./CNN3d-tflayers-model/')\n",
        "\n",
        "print(cnn3d_re.predict(X_ts_centered[:10,:,:,:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnyXZ2ibdnDV"
      },
      "source": [
        "preds = cnn3d_re.predict(X_ts_centered)\n",
        "\n",
        "print('Test Accuracy: {:.2f}'.format( 100 * np.sum(y_test == preds)/len(y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}